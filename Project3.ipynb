{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52c165f5-7170-49e5-bd76-486556be8316",
   "metadata": {
    "tags": []
   },
   "source": [
    "### NYC 311 calls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcab00fc-0814-478f-bb5b-e3ed0ac248fc",
   "metadata": {},
   "source": [
    "#### NYC 311 is a service that provides access to non-emergency City services and info about City government programs to the residents of New York.  Each year, the service receives millions of requests reporting various kinds of problems with city services and other issues.\n",
    "The data on the type of calls received, and their ultimate resolution is made available through the NYC Open Data portal at https://data.cityofnewyork.us/Social-Services/311-Service-Requests-from-2010-to-Present/erm2-nwe9. The data is updated daily.  The link also provides the data dictionary for the data.\n",
    "To ensure that we are all using the same data and arrive at the same results, the data has been downloaded and includes information up to 2023-08-04 12:00:00.  Several columns not required for this project have been removed from the original data.  (As an additional exercise to showcase your skills, you should feel free to download the entire dataset from the URL above for investigation.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56618fde-cfea-4c57-ba9c-a3604ab201a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data from the pickle file. Replace 'your_file_path' with the actual file path.\n",
    "df = pd.read_pickle('shared/Project-3_NYC_311_Calls.pkl')\n",
    "\n",
    "# Optimize numerical columns\n",
    "for col in df.select_dtypes(include=['int', \"float\"]).columns:\n",
    "    df[col] = pd.to_numeric(df[col], downcast='integer')\n",
    "\n",
    "# Convert object columns to category if they have a limited set of values\n",
    "for col in df.select_dtypes(include=['object']).columns:\n",
    "    if df[col].nunique() / len(df[col]) < 0.5:\n",
    "        df[col] = df[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d5ed60b-67f9-4ddf-b602-98c59d81ab8a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8684.320547945206\n"
     ]
    }
   ],
   "source": [
    "# Set the 'Created Date' as the index and convert it to a proper DatetimeIndex\n",
    "df = df.set_index(pd.DatetimeIndex(df['Created Date']))\n",
    "del df['Created Date']\n",
    "\n",
    "# Filtering the data for the year 2022\n",
    "df_2022 = df[df.index.year == 2022]\n",
    "\n",
    "# Calculating the average number of daily complaints in 2022\n",
    "# Assuming that each row represents a unique complaint\n",
    "average_daily_complaints_2022 = df_2022.resample('D')['Unique Key'].count().mean()\n",
    "\n",
    "# Print the result\n",
    "print(average_daily_complaints_2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "335041f3-a9bc-49a2-86d0-5ded73220e0d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-04 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Finding the date with the maximum number of calls\n",
    "max_calls_date = df.resample('D')['Unique Key'].count().idxmax()\n",
    "\n",
    "# Print the date\n",
    "print(max_calls_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a38cad1-adaf-4c82-8fc8-dc333bafd76e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common complaint on 2020-08-04: Damaged Tree\n"
     ]
    }
   ],
   "source": [
    "# First, find the date with the maximum number of calls\n",
    "max_calls_date = df.resample('D')['Unique Key'].count().idxmax()\n",
    "\n",
    "# Filter the dataframe for only the entries on that date\n",
    "df_max_calls_date = df[df.index.date == max_calls_date.date()]\n",
    "\n",
    "# Find the most common complaint type on that date\n",
    "most_common_complaint = df_max_calls_date['Complaint Type'].value_counts().idxmax()\n",
    "\n",
    "# Print the most common complaint type and the date\n",
    "print(f\"Most common complaint on {max_calls_date.date()}: {most_common_complaint}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7bc9127-a823-421d-a42d-281e5f1afa8f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quietest month historically: August\n"
     ]
    }
   ],
   "source": [
    "# Group the data by month and count the number of calls in each month\n",
    "monthly_calls = df.resample('M')['Unique Key'].count()\n",
    "\n",
    "# Identify the month with the fewest number of calls\n",
    "quietest_month = monthly_calls.idxmin().month_name()\n",
    "\n",
    "# Print the quietest month\n",
    "print(f\"The quietest month historically: {quietest_month}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "147f4a4c-8664-42c4-8032-34b661064041",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seasonal component value on 2020-12-25: 183\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# Resample the time series to a daily frequency\n",
    "daily_calls = df['Unique Key'].resample('D').count()\n",
    "\n",
    "# Perform ETS decomposition based on an additive model\n",
    "decomposition = sm.tsa.seasonal_decompose(daily_calls, model='additive')\n",
    "\n",
    "# Extract the seasonal component\n",
    "seasonal_component = decomposition.seasonal\n",
    "\n",
    "# Find the value of the seasonal component on 2020-12-25, rounded to the nearest integer\n",
    "seasonal_value = round(seasonal_component['2020-12-25'])\n",
    "\n",
    "# Print the seasonal value\n",
    "print(f\"Seasonal component value on 2020-12-25: {seasonal_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8af08764-a047-4349-9ef3-000cc8392603",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autocorrelation with a lag of 1 day: 0.7517059728398577\n"
     ]
    }
   ],
   "source": [
    "# Calculate the autocorrelation with lag 1\n",
    "autocorrelation_lag_1 = daily_calls.autocorr(lag=1)\n",
    "\n",
    "# Print the autocorrelation\n",
    "print(f\"Autocorrelation with a lag of 1 day: {autocorrelation_lag_1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ce66d2a-6a01-4eda-a164-0a3593f1df7d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          ds     y\n",
      "0 2010-01-01  2942\n",
      "1 2010-01-02  3958\n",
      "2 2010-01-03  5676\n",
      "3 2010-01-04  9763\n",
      "4 2010-01-05  8735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19:07:39 - cmdstanpy - INFO - Chain [1] start processing\n",
      "19:07:40 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1231.513760758433\n"
     ]
    }
   ],
   "source": [
    "from prophet import Prophet\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "import pandas as pd\n",
    "\n",
    "# Prepare the data for Prophet\n",
    "# Ensure the DataFrame is structured correctly\n",
    "prophet_df = pd.DataFrame({'ds': daily_calls.index, 'y': daily_calls.values})\n",
    "\n",
    "# Verify the structure of prophet_df\n",
    "print(prophet_df.head())  # Check the first few rows to ensure the structure is correct\n",
    "\n",
    "# Split into train and test sets\n",
    "train_df = prophet_df.iloc[:-90]\n",
    "test_df = prophet_df.iloc[-90:]\n",
    "\n",
    "# Initialize and fit the Prophet model\n",
    "model = Prophet()\n",
    "model.fit(train_df)\n",
    "\n",
    "# Make predictions\n",
    "future = model.make_future_dataframe(periods=90)\n",
    "forecast = model.predict(future)\n",
    "\n",
    "# Extract the predicted values for the test set\n",
    "predictions = forecast['yhat'].iloc[-90:]\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = sqrt(mean_squared_error(test_df['y'], predictions))\n",
    "\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149f4200-d8a7-4276-8e0f-46c699000ccc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mggy8413]",
   "language": "python",
   "name": "conda-env-mggy8413-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
